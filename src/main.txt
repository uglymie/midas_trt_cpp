#include <iostream>
#include "midas.h"
#include <libwebsockets.h>
using namespace cv;


VideoCapture cap("D://video/sample.mp4");
Mat frame;
std::string midas_model = "E:/py_projects/MiDaS/trt_cpp/model/dpt_swin2_tiny_256.trt";
Midas *midas; // (midas_model, 256);
std::unique_ptr<float> image_data;
std::unique_ptr<float> output_data;

void videodeal(lws *wsi);

static int callback(struct lws *wsi, enum lws_callback_reasons reason, void *user, void *in, size_t len)
{
    switch (reason)
    {
    case LWS_CALLBACK_ESTABLISHED:       // 当服务器和客户端完成握手后
        printf("Client connect!\n");
        midas = new Midas(midas_model, 256);
        break;
    case LWS_CALLBACK_RECEIVE:           // 当接收到客户端发来的
        printf("recvied message: %s\n", in);
        // lws_rx_flow_control( wsi, 0 );
        // 需要给客户端应答时，触发一次写回调
        lws_callback_on_writable( wsi );
        break;
    case LWS_CALLBACK_SERVER_WRITEABLE:
    {
        lwsl_user("LWS_CALLBACK_SERVER_WRITEABLE\n");
        // videodeal(wsi);
        // Read the next frame from the video file
        cap >> frame;
        if (frame.empty())
        {
            lwsl_notice("End of video\n");
            return -1; // End of video
        }

        image_data = midas->preprocessImage(frame, 256);

        // printData(image_data, 3 * 384 * 384, 10);
        auto start_time = std::chrono::high_resolution_clock::now();
        midas->runMonoDepth(image_data, output_data);
        auto end_time = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
        std::cout << "runMonoDepth " << duration.count() << " milliseconds." << std::endl;
        float fps = 1 / (duration.count() / 1000.0);
        std::cout << "Frames Per Second (FPS): "<< fps << std::endl;

        cv::Mat output_img = midas->postProcessing(output_data);
        cv::resize(output_img, output_img, cv::Size(320, 180));
        // cv::imshow("output_img", output_img);
        // cv::cvtColor(output_img,output_img,cv::COLOR_GRAY2BGR);
        cv::Mat scaled_img;
        cv::convertScaleAbs(output_img, scaled_img, 1.0 / 256.0);
        
        std::vector<uchar> img_buffer;
        imencode(".jpg", scaled_img, img_buffer);
        std::cout << "Encoded image size: " << img_buffer.size() << " bytes" << std::endl;

        unsigned char *buf = (unsigned char *)malloc(LWS_PRE + img_buffer.size() + LWS_SEND_BUFFER_POST_PADDING);
        memcpy(&buf[LWS_PRE], img_buffer.data(), img_buffer.size());
        lws_write(wsi, &buf[LWS_PRE], img_buffer.size(), LWS_WRITE_BINARY);
        free(buf);

        // Request another LWS_CALLBACK_SERVER_WRITEABLE event
        lws_callback_on_writable(wsi);
        // 下面的调用允许在此连接上接收数据
        // lws_rx_flow_control( wsi, 1 );

        break;
    }

    default:
        break;
    }

    return 0;
}

static struct lws_protocols protocols[] = {
    { "http", lws_callback_http_dummy, 0, 0, 0, NULL, 0},
    {"ws", callback, 0, 0},
    { NULL, NULL, 0, 0 } /* 最后一个协议必须是 NULL 结束的 */
};

static const struct lws_http_mount mount = {
	/* .mount_next */		NULL,		/* linked-list "next" */
	/* .mountpoint */		"/",		/* mountpoint URL */
	/* .origin */			"./video-stream",  /* serve from dir */
	/* .def */			"index.html",	/* default filename */
	/* .protocol */			NULL,
	/* .cgienv */			NULL,
	/* .extra_mimetypes */		NULL,
	/* .interpret */		NULL,
	/* .cgi_timeout */		0,
	/* .cache_max_age */		0,
	/* .auth_mask */		0,
	/* .cache_reusable */		0,
	/* .cache_revalidate */		0,
	/* .cache_intermediaries */	0,
	/* .origin_protocol */		LWSMPRO_FILE,	/* files in a dir */
	/* .mountpoint_len */		1,		/* char count */
	/* .basic_auth_login_file */	NULL,
};

void printData(const std::unique_ptr<float>& data, int data_size, int num_elements_to_print) {
    if (!data) {
        std::cout << "Data pointer is null." << std::endl;
        return;
    }

    int max_elements_to_print = num_elements_to_print * 2;  // 打印前后各10个元素

    for (int i = 0; i < data_size; ++i) {
        if (i < num_elements_to_print || i >= data_size - num_elements_to_print) {
            std::cout << std::setprecision(4) << "data[" << i << "] = " << data.get()[i] << std::endl;
        } else if (i == num_elements_to_print) {
            std::cout << "..." << std::endl;
        }
    }
}

void videodeal(lws *wsi)
{
    // std::string midas_model = "E:/py_projects/MiDaS/trt_cpp/model/dpt_swin2_large_384.trt";
    std::string midas_model = "E:/py_projects/MiDaS/trt_cpp/model/dpt_swin2_tiny_256.trt";
    Midas midas(midas_model, 256);
    std::unique_ptr<float> image_data;
    std::unique_ptr<float> output_data;

    cv::VideoCapture cap("D://video/sample.mp4");
    Mat frame;
    // 检查视频是否成功打开
    if (!cap.isOpened()) {
        std::cerr << "Error: Could not open video file." << std::endl;
        return;
    }
    
    while (1)
    {

        cap >> frame;
        if (frame.empty())
        {
            lwsl_notice("End of video\n");
            return; // End of video
        }

        image_data = midas.preprocessImage(frame, 256);

        // printData(image_data, 3 * 384 * 384, 10);
        auto start_time = std::chrono::high_resolution_clock::now();
        midas.runMonoDepth(image_data, output_data);
        auto end_time = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
        std::cout << "runMonoDepth " << duration.count() << " milliseconds." << std::endl;
        float fps = 1 / (duration.count() / 1000.0);
        std::cout << "Frames Per Second (FPS): "<< fps << std::endl;

        cv::Mat output_img = midas.postProcessing(output_data);
        // cv::resize(output_img, output_img, cv::Size(320, 180));
        // cv::imshow("output_img", output_img);

        std::vector<uchar> img_buffer;
        imencode(".jpg", output_img, img_buffer);

        unsigned char *buf = (unsigned char *)malloc(LWS_PRE + img_buffer.size() + LWS_SEND_BUFFER_POST_PADDING);
        memcpy(&buf[LWS_PRE], img_buffer.data(), img_buffer.size());
        lws_write(wsi, &buf[LWS_PRE], img_buffer.size(), LWS_WRITE_BINARY);
        free(buf);

        
    }
}

int main(int, char**){
    
    // 创建 WebSocket 监听端口
    struct lws_context_creation_info info;
    static struct lws_context *context;
	int n = 0, logs = LLL_USER | LLL_ERR | LLL_WARN | LLL_NOTICE;
    
	lws_set_log_level(logs, NULL);
	lwsl_user("LWS minimal ws server | visit http://localhost:9002 (-s = use TLS / https)\n");

    memset(&info, 0, sizeof(info));
    info.port = 9002; // 替换为你的 WebSocket 端口号
    info.iface = NULL;
    info.protocols = protocols;
    info.mounts = &mount;
    info.extensions = NULL;
    info.gid = -1;
    info.uid = -1;
    info.options = 0;
    info.vhost_name = "168.168.0.17";

    context = lws_create_context(&info);
    if (!context) {
        fprintf(stderr, "WebSocket context creation failed.\n");
        return -1;
    }
    printf("WebSocket server started. Listening on port %d...\n", info.port);


    while (1)
    {
        lws_service(context, 50); // 50 ms timeout for event handling
    }

    // 关闭 WebSocket 连接
    lws_context_destroy(context);
    return 0;
}
